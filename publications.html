<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Stan Birchfield - Publications</title>
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap">
    <style>
        .publications-container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            font-family: 'Lato', sans-serif;
            line-height: 1.6;
            color: #333;
        }
        
        .publications-header {
            text-align: center;
            margin-bottom: 30px;
            padding: 20px 0;
            background-color: #f8f9fa;
            border-radius: 8px;
        }
        
        .publications-header h1 {
            font-size: 2.5em;
            font-weight: 700;
            color: #2c3e50;
            margin: 0;
        }
        
        
        .year-section {
            margin-bottom: 40px;
        }
        
        .year-section h3 {
            font-size: 1.8em;
            font-weight: 700;
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        
        .publication-item {
            margin-bottom: 25px;
            padding: 15px;
            background-color: #fff;
            border: 1px solid #e9ecef;
            border-radius: 8px;
            transition: box-shadow 0.3s ease;
        }
        
        .publication-item:hover {
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
        }
        
        .publication-title {
            font-weight: 700;
            font-size: 1.1em;
            margin-bottom: 8px;
        }
        
        .publication-title a {
            color: #2c3e50;
            text-decoration: none;
        }
        
        .publication-title a:hover {
            color: #3498db;
        }
        
        .publication-links {
            margin: 8px 0;
            font-size: 14px;
        }
        
        .publication-links a {
            color: #3498db;
            text-decoration: none;
        }
        
        .publication-links a:hover {
            text-decoration: underline;
        }
        
        .publication-authors {
            font-style: italic;
            margin: 8px 0;
            color: #555;
        }
        
        .publication-venue {
            font-style: italic;
            margin: 8px 0;
            color: #666;
        }
        
        .publication-news {
            color: #76b900;
            margin: 8px 0;
            font-size: 14px;
        }
        
        .publication-news strong {
            color: #76b900;
        }
        
        .publication-news a {
            color: #76b900;
            text-decoration: none;
        }
        
        .publication-news a:hover {
            text-decoration: underline;
        }
        
        .youtube-icon {
            height: 17px;
            vertical-align: middle;
            margin-left: 5px;
        }
        
        .ppt-icon {
            height: 17px;
            vertical-align: middle;
            margin-left: 5px;
        }
        
        .copyright-notice {
            margin-top: 40px;
            padding: 20px;
            background-color: #f8f9fa;
            border-radius: 8px;
            font-size: 14px;
            color: #666;
            font-style: italic;
        }
        
        @media (max-width: 768px) {
            .publications-container {
                padding: 15px;
            }
            
            .publications-header h1 {
                font-size: 2em;
            }
            
            .year-section h3 {
                font-size: 1.5em;
            }
            
            .publication-links a {
                display: block;
                margin-bottom: 5px;
            }
        }
    </style>
</head>
<body>
    <nav class="navbar">
        <div class="nav-container">
            <ul class="nav-links">
                <li><a href="index.html#home">Home</a></li>
                <li><a href="index.html#about">About</a></li>
                <li><a href="index.html#publications">Publications</a></li>
                <li><a href="index.html#book">Book</a></li>
                <li><a href="index.html#teaching">Teaching</a></li>
            </ul>
        </div>
    </nav>

    <div class="publications-container">
        <div class="publications-header">
            <h1>Complete List of Publications</h1>
        </div>
        
        <div class="year-section">
            <h3>2025</h3>
            <div class="publication-item">
                <div class="publication-title">
                    FoundationStereo: Zero-Shot Stereo Matching
                </div>
                <div class="publication-authors">B. Wen, M. Trepte, J. Aribido, J. Kautz, O. Gallo, S. Birchfield</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Nashville, Tennessee, June 2025</div>
                <div class="publication-news">
                    <strong>News:</strong> <a href="https://cvpr.thecvf.com/virtual/2025/events/AwardCandidates2025">CVPR Best Paper Award Candidate</a>
                </div>
                <div class="publication-news">
                    <strong>News:</strong> <a href="https://vision.middlebury.edu/stereo/eval3">#1 on Middlebury Stereo Evaluation - Version 3</a> <span style="color: #777777">(2025/02/03 – 2025/03/04)</span>
                </div>
                <div class="publication-news">
                    <strong>News:</strong> <a href="https://www.eth3d.net/low_res_two_view">#1 on ETH3D Low-Res Two-View Benchmark</a> <span style="color: #777777">(2024/11/15 – 2025/05/14)</span>
                </div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2501.09898">Paper</a> |
                    <a href="https://github.com/NVlabs/FoundationStereo">Code and Dataset</a> |
                    <a href="https://youtu.be/R7RgHxEXB3o">Video</a> |
                    <a href="https://nvlabs.github.io/FoundationStereo">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics
                </div>
                <div class="publication-authors">C. H. Song, V. Blukis, J. Tremblay, S. Tyree, Y. Su, S. Birchfield</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Nashville, Tennessee, June 2025</div>
                <div class="publication-venue">Also in CVPR Workshop on Emergent Visual Abilities and Limits of Foundation Models (EVAL-FoMo-2), Nashville, Tennessee, June 2025</div>
                <div class="publication-venue">Also in CVPR Workshop on 3D-LLM/VLA, Nashville, Tennessee, June 2025</div>
                <div class="publication-venue">Also in ICLR Robot Learning Workshop: Towards Robots with Human-Level Abilities, Singapore, April 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2411.16537">Paper</a> |
                    <a href="https://github.com/NVlabs/RoboSpatial">Code</a> |
                    <a href="https://huggingface.co/datasets/chanhee-luke/RoboSpatial-Home">Dataset</a> |
                    <a href="https://chanh.ee/RoboSpatial">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    SPOT: SE(3) Pose Trajectory Diffusion for Object-Centric Manipulation
                </div>
                <div class="publication-authors">C.-C. Hsu, B. Wen, J. Xu, Y. Narang, X. Wang, Y. Zhu, J. Biswas, S. Birchfield</div>
                <div class="publication-venue">International Conference on Robotics and Automation (ICRA), Atlanta, May 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2411.00965">Paper</a> |
                    <a href="https://github.com/NVlabs/object_centric_diffusion">Code</a> |
                    <a href="https://youtu.be/yktAPZ1ERnQ">Video</a> |
                    <a href="https://nvlabs.github.io/object_centric_diffusion">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    3D-Generalist: Self-Improving Vision-Language-Action Models for Crafting 3D Worlds
                </div>
                <div class="publication-authors">F.-Y. Sun, S. Wu, C. Jacobsen, T. Yim, H. Zou, A. Zook, S. Li, Y.-H. Chou, E. Can, X. Wu, C. Eppner, V. Blukis, J. Tremblay, J. Wu, S. Birchfield, N. Haber</div>
                <div class="publication-venue">arXiv:2507.06484, July 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2507.06484">Paper</a> |
                    <a href="https://ai.stanford.edu/~sunfanyun/3d-generalist/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    GraspGen: A Diffusion-based Framework for 6-DOF Grasping with On-Generator Training
                </div>
                <div class="publication-authors">A. Murali, B. Sundaralingam, Y.-W. Chao, W. Yuan, J. Yamada, M. Carlson, F. Ramos, S. Birchfield, D. Fox, C. Eppner</div>
                <div class="publication-venue">arXiv:2507.13097, July 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2507.13097">Paper</a> |
                    <a href="https://github.com/NVlabs/GraspGen">Code</a> |
                    <a href="https://youtu.be/gM5fgK2aZ1Y">Video</a> |
                    <a href="https://graspgen.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    RaySt3R: Predicting Novel Depth Maps for Zero-Shot Object Completion
                </div>
                <div class="publication-authors">B. P. Duisterhof, J. Oberst, B. Wen, S. Birchfield, D. Ramanan, J. Ichnowski</div>
                <div class="publication-venue">arXiv:2506.05285, June 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2506.05285">Paper</a> |
                    <a href="https://github.com/Duisterhof/rayst3r">Code</a> |
                    <a href="https://rayst3r.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    BOP Challenge 2024 on Model-Based and Model-Free 6D Object Pose Estimation
                </div>
                <div class="publication-authors">V. N. Nguyen, S. Tyree, A. Guo, M. Fourmy, A. Gouda, T. Lee, S. Moon, H. Son, L. Ranftl, J. Tremblay, E. Brachmann, B. Drost, V. Lepetit, C. Rother, S. Birchfield, J. Matas, Y. Labbe, M. Sundermeyer, T. Hodan</div>
                <div class="publication-venue">CVPR Workshop on Computer Vision for Mixed Reality (CV4MR), Nashville, Tennessee, June 2025</div>
                <div class="publication-news">
                    <strong>Award:</strong> CV4MR Workshop Best Paper Award
                </div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2504.02812">Paper</a> |
                    <a href="https://bop.felk.cvut.cz/home/">Benchmark</a> |
                    <a href="https://cv4mr.github.io/">Workshop</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    OG-VLA: 3D-Aware Vision Language Action Model via Orthographic Image Generation
                </div>
                <div class="publication-authors">I. Singh, A. Goyal, S. Birchfield, D. Fox, A. Garg, V. Blukis</div>
                <div class="publication-venue">arXiv:2506.01196, June 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2506.01196">Paper</a> |
                    <a href="https://og-vla.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Mitigating Covariate Shift in Imitation Learning for Autonomous Vehicles Using Latent Space Generative World Models
                </div>
                <div class="publication-authors">A. Popov, A. Degirmenci, D. Wehr, S. Hegde, R. Oldja, A. Kamenev, B. Douillard, D. Nistér, U. Muller, R. Bhargava, S. Birchfield, N. Smolyanskiy</div>
                <div class="publication-venue">ICRA Robots in the Wild Workshop, Atlanta, May 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2409.16663">Paper</a> |
                    <a href="https://youtu.be/fO7RZ57gVxk">Video</a> |
                    <a href="https://2025.ieee-icra.org/event/robots-in-the-wild/">Workshop</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">Towards a VLM Benchmark for Simulated Robotics</div>
                <div class="publication-authors">X. Yang, C. Eppner, V. Blukis, P. Belcak, S. Tyree, D. Fox, S. Birchfield, F. Ramos, J. Tremblay</div>
                    <div class="publication-venue">RSS Workshop on Large Foundation Model for Interactive Robot Learning (LFM), Los Angeles, June 2025</div>
                <div class="publication-links">
                    <a href="https://lfmrss2025.weebly.com/">Workshop</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    GRS: Generating Robotic Simulation Tasks from Real-World Images
                </div>
                <div class="publication-authors">A. Zook, F.-Y. Sun, J. Spjut, V. Blukis, S. Birchfield, J. Tremblay</div>
                <div class="publication-venue">CVPR Workshop on Computer Vision for Video Games (CV2), Nashville, Tennessee, June 2025</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2410.15536">Paper</a> |
                    <a href="https://sites.google.com/view/cv2-2025/program">Workshop</a>
                </div>
            </div>
        </div>

        <div class="year-section">
            <h3>2024</h3>
            <div class="publication-item">
                <div class="publication-title">
                    FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects
                </div>
                <div class="publication-authors">B. Wen, W. Yang, J. Kautz, S. Birchfield</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Seattle, June 2024</div>
                <div class="publication-news">
                    <strong>Award:</strong> <a href="https://cecas.clemson.edu/~stb/publications/FoundationPose_award_BOP24.png">BOP Challenge 2024 "Early Bird" Award</a>
                </div>
                <div class="publication-news">
                    <strong>News:</strong> <a href="https://bop.felk.cvut.cz/leaderboards/pose-estimation-unseen-bop23/bop-classic-core/">#1 on BOP leaderboard for unseen 6D pose estimation</a> <span style="color: #777777">(2023/11/19 – 2024/09/03)</span>
                </div>
                <div class="publication-news">
                    <strong>Press:</strong> <a href="https://www.linkedin.com/posts/nvidia-ai_nvidiaresearch-activity-7141488010151276546-2ov8?utm_source=share&utm_medium=member_desktop">NVIDIA AI post</a>
                </div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2312.08344">Paper</a> |
                    <a href="https://github.com/NVlabs/FoundationPose">Code</a> |
                    <a href="https://youtu.be/Ip_yWsGUF6c">Video</a> |
                    <a href="https://nvlabs.github.io/FoundationPose">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects
                </div>
                <div class="publication-authors">Y. Weng, B. Wen, J. Tremblay, V. Blukis, D. Fox, L. Guibas, S. Birchfield</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Seattle, June 2024</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2404.01440">Paper</a> |
                    <a href="https://github.com/NVlabs/DigitalTwinArt">Code</a> |
                    <a href="https://nvlabs.github.io/DigitalTwinArt/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    NeRFDeformer: NeRF Transformation from a Single View via 3D Scene Flows
                </div>
                <div class="publication-authors">Z. Tang, Z. Ren, X. Zhao, B. Wen, J. Tremblay, S. Birchfield, A. Schwing</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Seattle, June 2024</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2406.10543">Paper</a> |
                    <a href="https://youtu.be/oZsA6i9g_yM">Video</a> |
                    <a href="https://github.com/nerfdeformer/nerfdeformer">Code</a> |
                    <a href="https://nerfdeformer.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    DeformGS: Scene Flow in Highly Deformable Scenes for Deformable Object Manipulation
                </div>
                <div class="publication-authors">B. P. Duisterhof, M. Zhao, Y. Yao, J.-W. Liu, J. Seidenschwarz, M. Z. Shou, D. Ramanan, S. Song, S. Birchfield, B. Wen, J. Ichnowski</div>
                <div class="publication-venue">Workshop on the Algorithmic Foundations of Robotics (WAFR), Chicago, October 2024</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2312.00583">Paper</a> |
                    <a href="https://github.com/momentum-robotics-lab/deformgs">Code</a> |
                    <a href="https://deformgs.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Partial-View Object View Synthesis via Filtered Inversion
                </div>
                <div class="publication-authors">F.-Y. Sun, J. Tremblay, V. Blukis, K. Lin, D. Xu, B. Ivanovic, P. Karkus, S. Birchfield, D. Fox, R. Zhang, Y. Li, J. Wu, M. Pavone, N. Haber</div>
                <div class="publication-venue">3DV, Davos, Switzerland, March 2024</div>
                <div class="publication-venue">Also in CVPR Workshop on Advances in NeRF for the Metaverse (XRNeRF), Vancouver, June 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2304.00673">Paper</a> |
                    <a href="https://github.com/sunfanyunn/FINV">Code</a> |
                    <a href="https://cs.stanford.edu/~sunfanyun/finv">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Unlocking the Secrets of Linear Complexity Sequence Model from A Unified Perspective
                </div>
                <div class="publication-authors">Z. Qin, X. Shen, W. Sun, D. Li, S. Birchfield, R. Hartley, Y. Zhong</div>
                <div class="publication-venue">ICML Workshop on Next Generation of Sequence Modeling Architectures, Vienna, Austria, July 2024</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2405.17383">Paper</a> |
                    <a href="https://sites.google.com/view/ngsmworkshop">Workshop</a>
                </div>
            </div>
        </div>

        <div class="year-section">
            <h3>2023</h3>
            <div class="publication-item">
                <div class="publication-title">
                    HANDAL: A Dataset of Real-World Manipulable Object Categories with Pose Annotations, Affordances, and Reconstructions
                </div>
                <div class="publication-authors">A. Guo, B. Wen, J. Yuan, J. Tremblay, S. Tyree, J. Smith, S. Birchfield</div>
                <div class="publication-venue">International Conference on Intelligent Robots and Systems (IROS), Detroit, Michigan, October 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2308.01477">Paper</a> |
                    <a href="https://github.com/NVlabs/HANDAL">Code</a> |
                    <a href="https://nvlabs.github.io/HANDAL">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    BundleSDF: Neural 6-DoF Tracking and 3D Reconstruction of Unknown Objects
                </div>
                <div class="publication-authors">B. Wen, J. Tremblay, V. Blukis, S. Tyree, T. Müller, A. Evans, D. Fox, J. Kautz, S. Birchfield</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Vancouver, June 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2303.14158">Paper</a> |
                    <a href="https://github.com/NVlabs/BundleSDF">Code</a> |
                    <a href="https://youtu.be/XH5t0wEH3d0">Video</a> |
                    <a href="https://bundlesdf.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    TTA-COPE: Test-Time Adaptation for Category-Level Object Pose Estimation
                </div>
                <div class="publication-authors">T. Lee, J. Tremblay, V. Blukis, B. Wen, B.-U. Lee, I. Shin, S. Birchfield, I. S. Kweon, K.-J. Yoon</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Vancouver, June 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2303.16730">Paper</a> |
                    <a href="https://youtu.be/MUgQ0yithis">Video</a> |
                    <a href="https://sites.google.com/view/taeyeop-lee/ttacope">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Affordance Diffusion: Synthesizing Hand-Object Interactions
                </div>
                <div class="publication-authors">Y. Ye, X. Li, A. Gupta, S. De Mello, S. Birchfield, J. Song, S. Tulsiani, S. Liu</div>
                <div class="publication-venue">Computer Vision and Pattern Recognition (CVPR), Vancouver, June 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2303.12538">Paper</a> |
                    <a href="https://youtu.be/omhEoLzsopo">Video</a> |
                    <a href="https://judyye.github.io/affordiffusion-www">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Parallel Inversion of Neural Radiance Fields for Robust Pose Estimation
                </div>
                <div class="publication-authors">Y. Lin, T. Müller, J. Tremblay, B. Wen, S. Tyree, A. Evans, P. A. Vela, S. Birchfield</div>
                <div class="publication-venue">International Conference on Robotics and Automation (ICRA), London, May 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2210.10108">Paper</a> |
                    <a href="https://github.com/NVlabs/ParallelInversion">Code</a> |
                    <a href="https://pnerfp.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    RGB-Only Reconstruction of Tabletop Scenes for Collision-Free Manipulator Control
                </div>
                <div class="publication-authors">Z. Tang, B. Sundaralingam, J. Tremblay, B. Wen, Y. Yuan, S. Tyree, C. Loop, A. Schwing, S. Birchfield</div>
                <div class="publication-venue">International Conference on Robotics and Automation (ICRA), London, May 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2210.11668">Paper</a> |
                    <a href="https://youtu.be/Bn1w9y5aYYg">Video</a> |
                    <a href="https://ngp-mpc.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    One-Shot Neural Fields for 3D Object Understanding
                </div>
                <div class="publication-authors">V. Blukis, T. Lee, J. Tremblay, B. Wen, I. S. Kweon, K.-J. Yoon, D. Fox, S. Birchfield</div>
                <div class="publication-venue">CVPR Workshop on Advances in NeRF for the Metaverse (XRNeRF), Vancouver, June 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2210.12126">Paper</a> |
                    <a href="https://youtu.be/sHVMp8XdUN4">Video</a> |
                    <a href="https://nerfgrasp.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Vicinity Vision Transformer
                </div>
                <div class="publication-authors">W. Sun, Z. Qin, H. Deng, J. Wang, Y. Zhang, K. Zhang, N. Barnes, S. Birchfield, L. Kong, Y. Zhong</div>
                <div class="publication-venue">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 45(10):12635-12649, October 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2206.10552">Paper</a> |
                    <a href="https://github.com/OpenNLPLab/Vicinity-Vision-Transformer">Code</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Diff-DOPE: Differentiable Deep Object Pose Estimation
                </div>
                <div class="publication-authors">J. Tremblay, B. Wen, V. Blukis, B. Sundaralingam, S. Tyree, S. Birchfield</div>
                <div class="publication-venue">arXiv:2310.00463, October 2023</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2310.00463">Paper</a> | 
                    <a href="https://youtu.be/LOzd63TJxJs">Video</a> | 
                    <a href="https://diffdope.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Audio-Visual Segmentation with Semantics
                </div>
                <div class="publication-authors">J. Zhou, X. Shen, J. Wang, J. Zhang, W. Sun, J. Zhang, S. Birchfield, D. Guo, L. Kong, M. Wang, Y. Zhong</div>
                <div class="publication-venue">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) - submitted</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2301.13190">Paper</a> | 
                    <a href="https://github.com/OpenNLPLab/AVSBench">Code</a> | 
                    <a href="https://opennlplab.github.io/AVSBench/">Website</a>
                </div>
            </div>
        </div>

        <div class="year-section">
            <h3>2022</h3>
            <div class="publication-item">
                <div class="publication-title">
                    MegaPose: 6D Pose Estimation of Novel Objects via Render & Compare
                </div>
                <div class="publication-authors">Y. Labbé, L. Manuelli, A. Mousavian, S. Tyree, S. Birchfield, J. Tremblay, J. Carpentier, M. Aubry, D. Fox, J. Sivic</div>
                <div class="publication-venue">Conference on Robot Learning (CoRL), Auckland, New Zealand, December 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2212.06870">Paper</a> | 
                    <a href="https://megapose6d.github.io/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    6-DoF Pose Estimation of Household Objects for Robotic Manipulation: An Accessible Dataset and Benchmark
                </div>
                <div class="publication-authors">S. Tyree, J. Tremblay, T. To, J. Cheng, T. Mosier, J. Smith, S. Birchfield</div>
                <div class="publication-venue">International Conference on Intelligent Robots and Systems (IROS), Kyoto, Japan, October 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2203.05701">Paper</a> | 
                    <a href="https://github.com/swtyree/hope-dataset">Code and Dataset</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Audio-Visual Segmentation
                </div>
                <div class="publication-authors">J. Zhou, J. Wang, J. Zhang, W. Sun, J. Zhang, S. Birchfield, D. Guo, L. Kong, M. Wang, Y. Zhong</div>
                <div class="publication-venue">European Conference on Computer Vision (ECCV), Tel-Aviv, Israel, October 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2207.05042">Paper</a> | 
                    <a href="https://github.com/OpenNLPLab/AVSBench">Code</a> | 
                    <a href="https://opennlplab.github.io/AVSBench/">Website</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    PredictionNet: Real-Time Joint Probabilistic Traffic Prediction for Planning, Control, and Simulation
                </div>
                <div class="publication-authors">A. Kamenev, L. Wang, O. B. Bohan, I. Kulkarni, B. Kartal, A. Molchanov, S. Birchfield, D. Nistér, N. Smolyanskiy</div>
                <div class="publication-venue">International Conference on Robotics and Automation (ICRA), Philadelphia, Pennsylvania, May 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2109.11094">Paper</a> |
                    <a href="https://www.youtube.com/watch?v=C7Nb3DRjFP0">Video</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Single-Stage Keypoint-Based Category-Level Object Pose Estimation from an RGB Image
                </div>
                <div class="publication-authors">Y. Lin, J. Tremblay, S. Tyree, P. A. Vela, S. Birchfield</div>
                <div class="publication-venue">International Conference on Robotics and Automation (ICRA), Philadelphia, Pennsylvania, May 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2109.06161">Paper</a> |
                    <a href="https://sites.google.com/view/centerpose">Website</a> | 
                    <a href="https://github.com/NVlabs/CenterPose">Code</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Keypoint-Based Category-Level Object Pose Tracking from an RGB Sequence with Uncertainty Estimation
                </div>
                <div class="publication-authors">Y. Lin, J. Tremblay, S. Tyree, P. A. Vela, S. Birchfield</div>
                <div class="publication-venue">International Conference on Robotics and Automation (ICRA), Philadelphia, Pennsylvania, May 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2205.11047">Paper</a> | 
                    <a href="https://sites.google.com/view/centerposetrack">Website</a> | 
                    <a href="https://github.com/NVlabs/CenterPose">Code</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    Displacement-Invariant Cost Computation for Stereo Matching
                </div>
                <div class="publication-authors">Y. Zhong, C. Loop, W. Byeon, S. Birchfield, Y. Dai, K. Zhang, A. Kamenev, T. Breuel, H. Li, J. Kautz</div>
                <div class="publication-venue">International Journal of Computer Vision (IJCV), 130(5):1196-1209, May 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2012.00899">Paper</a> | 
                    <a href="https://link.springer.com/article/10.1007/s11263-022-01595-8">Journal version</a>
                </div>
            </div>
            
            <div class="publication-item">
                <div class="publication-title">
                    RTMV: A Ray-Traced Multi-View Synthetic Dataset for Novel View Synthesis
                </div>
                <div class="publication-authors">J. Tremblay*, M. Meshry*, A. Evans, J. Kautz, A. Keller, S. Khamis, C. Loop, N. Morrical, T. Müller, K. Nagano, T. Takikawa, S. Birchfield</div>
                <div class="publication-venue">ECCV Workshop on Learning to Generate 3D Shapes and Scenes, Tel-Aviv, Israel, October 2022</div>
                <div class="publication-links">
                    <a href="https://arxiv.org/abs/2205.07058">Paper</a> | 
                    <a href="https://learn3dg.github.io/">Workshop</a>
                </div>
            </div>
        </div>

        <p class="full-pubs-link"><a href="https://cecas.clemson.edu/~stb/publications/" target="_blank">Complete list of older publications<i class="fas fa-external-link-alt"></i></a></p>

        <!-- Continue with remaining years... -->
        <!-- For brevity, I'll add a note that the rest of the years would follow the same pattern -->
        
        <div class="copyright-notice">
            <i>Notice:</i> This material is presented to ensure timely dissemination of scholarly and technical work. Copyright and all rights therein are retained by authors or by other copyright holders. All persons copying this information are expected to adhere to the terms and constraints invoked by each author's copyright. In most cases, these works may not be reposted without the explicit permission of the copyright holder.
        </div>
    </div>
</body>
</html>